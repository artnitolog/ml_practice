\documentclass[12pt]{article}


\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{substitutefont}
\usepackage[english, russian]{babel}
% \substitutefont{T2A}{\rmdefault}{XCharter}
\usepackage[sups]{XCharter}
\usepackage[vvarbb, uprightscript,charter, scaled=1.05]{newtxmath}
% \usepackage{amsmath}
\usepackage{enumitem}
% \setmathfont{Stix Math}[version=stix]
% \usepackage{paratype}
\usepackage{verbatim}
% \usepackage{caption}
% \captionsetup[figure]{skip=1pt}
% \usepackage{microtype}
\usepackage[style=numeric, sorting=none]{biblatex}
\addbibresource{refs.bib}
% \usepackage{minted}
% \usepackage{fancyhdr}
% \usepackage{gensymb}
\usepackage{booktabs}
% \usepackage{ntheorem}
% \usepackage{mathtools}
\usepackage{geometry}
% \usepackage{titling}  
\usepackage{indentfirst}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{graphicx}
\graphicspath{ {../vis/} }

\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\usepackage{biblatex}

\geometry{a4paper, textwidth=16cm, textheight=24cm}

\DeclareMathOperator{\sign}{sign}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\pder}[2][]{\frac{\partial#1}{\partial#2}}
\newcommand\mbtw[1]{{\color{gray}#1}}
\newcommand{\mpl}[2]{
    \begin{figure}[!h]
        \includegraphics[width=0.98\textwidth]{#1}
        \centering
        \caption{#2}
        \label{fig:#1}
     \end{figure}
}

\title{Отчет по заданию №2:\break Применение линейных моделей для определения токсичности комментария}
\author{Васильев Руслан \and{ВМК МГУ, 317 группа}}

\begin{document}

\maketitle
\tableofcontents
\newpage
\section{Теория}
В данном разделе раскрываются некоторые теоретические аспекты логистической регрессии. Обосновывается эквивалентность двух подходов: метода минимизации эмпирического риска (функции потерь для всей выборки) и вероятностной модели. Также рассматривается обобщение для задачи многоклассовой классификации. Обозначения и логика рассуждений во многом соответствуют \cite{voron}. Все векторы (например, признаков или весов) в матричных выражениях, если не указано, рассматриваются как вектор-столбцы.
\subsection{Общая постановка}
В стандартной постановке задачи бинарной классификации рассматривается обучающая выборка 
\begin{equation*}
    \mathbb{X}=(\vec{x}_i, y_i)_{i=1}^{l}, \quad
    \begin{array}{l}
        \vec{x}_i\in \mathbb{R}^d \text{ --- объекты (их признаковые описания)}, \\
        y_i \in \left\{-1,+1\right\}\text{ ---~метки классов}.
    \end{array}
\end{equation*}
Считая, что среди признаков есть константный, в линейной модели можно представить (бинарные) ответы алгоритма следующим образом:
\begin{equation*}
    a(\vec{x}, \vec{w}) = \sign{\left<\vec{x}, \vec{w}\right>},\quad \vec{w} \in \mathbb{R}^d \text{ ---~вектор весов.}
\end{equation*}
Вместо пороговой фунции потерь $\mathcal{L}_{\mathbb{1}}$ мы используем верхнюю оценку~--- гладкую аппроксимацию $\mathcal{L}$:
\begin{equation}
    \label{eq:loss_approx}
    \mathcal{L}_{\mathbb{1}}(y, a)
    = \left[a \cdot y < 0\right]
    = [\left<\vec{x}, \vec{w}\right> y< 0]
    \leqslant \mathcal{L}(\mkern-55mu\underbrace{\left<\vec{x}, \vec{w}\right>y}_{M(\vec{w})\text{ --- отступ на объекте }\vec{x}}\mkern-53mu)
    \leqslant \mathcal{L}(M),
\end{equation}
причем процесс обучения представляет собой поиск оптимального $\vec{w}$, минимизирующего эмпирический риск:
\begin{equation}
    \label{eq:empmin}
    Q(\mathbb{X}, \vec{w}) = \frac{1}{l}\sum_{i=1}^l\,
    [\,\underbrace{\left<\vec{x}_i, \vec{w}\right>y_{i}}_{M_i(\vec{w})} <0\,]
    \leqslant
    \frac{1}{l}\sum_{i=1}^l\,
    \mathcal{L}\left({M_i(\vec{w}})\right)\; \rightarrow \;\min_\vec{w}.
\end{equation}

Для решения задачи обычно используются градиентные методы, требующие вычисление градиента $\pder[\mathcal{L}]{\vec{w}}$. Также к минимизируемому функционалу \eqref{eq:empmin} могут добавляться дополнительные слагаемые-регуляризаторы. Например, в данной работе используется $L_2$-регуляризатор, с которым задача имеет вид:
\begin{equation}
    \widetilde{Q}(\mathbb{X}, \vec{w}) = \frac{1}{l}\sum_{i=1}^l\,
    \mathcal{L}\left({M_i(\vec{w}})\right) + \frac{\lambda}{2}\|\vec{w}\|^2\;\rightarrow \;\min_\vec{w}.
\end{equation}
Градиент квадратичного регуляризатора вычисляется тривиально:
\begin{equation}
    \label{eq:loss_reg}
    \pder{\vec{w}}\left(\frac{\lambda}{2}\|\vec{w}\|^2\right) = \frac{\lambda}{2}\cdot 2\vec{w} = \lambda \vec{w}.
\end{equation}

\subsection{Бинарная логистическая регрессия}
\subsubsection{С точки зрения минимизации эмпирического риска}
Рассмотрим следующую функцию потерь\footnote{Заметим, что для выполнения неравенства\eqref{eq:loss_approx} основание логарифма должно быть в пределах $(1, 2]$. Но в силу свойств логарифма выбор основания будет влиять исключительно на масштаб, поэтому для удобства обычно бурут $e$.} — ее обычно называют логарифмической или логистической:
\begin{equation}
    \label{eq:old_logloss}
    \mathcal{L}(M) = \log{(1+e^{-M})}=
    \log{(1+e^{-\left<\vec{x},\vec{w}\right>y})}\,,
\end{equation}
частная производная которой
\begin{align}
    \pder[\mathcal{L}]{\vec{w}}
    &=\pder{\vec{w}}\log{(1+e^{-\left<\vec{x},\vec{w}\right>y})} \nonumber\\
    &=\frac{1}{1+e^{-\left<\vec{x},\vec{w}\right>y}}\cdot\pder{\vec{w}}(1+e^{-\left<\vec{x},\vec{w}\right>y}) \nonumber\\
    &=\frac{e^{-\left<\vec{x},\vec{w}\right>y}}{1+e^{-\left<\vec{x},\vec{w}\right>y}}\cdot\pder{\vec{w}}(-\left<\vec{x},\vec{w}\right>y) \nonumber\\
    &=\frac{1}{1+e^{\left<\vec{x},\vec{w}\right>y}}\cdot(-y\vec{x}) \nonumber\\
    &= \label{eq:loss_okay}-y \sigma\left(-\left<\vec{x},\vec{w}\right>y\right)\cdot\vec{x}\,,
\end{align}
где с помощью $\sigma$ мы обозначили сигмоиду:
\begin{equation*}
    \sigma{\left(s\right)}=\frac{1}{1+e^{-s}}.
\end{equation*}
Таким образом, на всей выборке имеем:
\begin{equation}
    \label{eq:whole_loss}
    \pder[\widetilde{Q}]{\vec{w}}=
    \pder[{Q}]{\vec{w}} + \lambda{\vec{w}}=-\frac{1}{l}\sum_{i=1}^l y_i \sigma\left(-\left<\vec{x}_i,\vec{w}\right>y_i\right)\cdot\vec{x}_i+\lambda{\vec{w}}.
\end{equation}

\subsubsection{С точки зрения вероятностной модели}
Возьмем следующую модель условной вероятности:
\begin{align}
    \label{eq:bernoulli}
    y \mid \vec{x},\vec{w} \sim \text{Be}\left\{\sigma\left(\left<\vec{x},\vec{w}\right>\right)\right\},
\end{align}
то есть $y\in\{0, 1\}$ качестве ответов алгоритма будем брать небинаризованные вероятности:
\begin{gather}
    \label{eq:a_logregr}
    a(\vec{x}) = \mathbb{P}(y=1 | \vec{x}, \vec{w})=
    \sigma\left(\left<\vec{x},\vec{w}\right>\right)
\end{gather}
Можно искать параметр $\vec{w}$ методом максимального правдоподобия. Это эквивалентно минимизации логарифма правдоподобия выборки, взятого со знаком минус ($a_i$~--- ответ на $i$-м объекте):
\begin{gather*}
    -l(\vec{w})=-\log\prod_{i=1}^{l}\mathbb{P}(y_i | \vec{x}_i, \vec{w}) =
    -\log\prod_{i=1}^{l}a_i^{y_i}(1-a_i)^{1-y_i} = \\
    =\sum_{i=1}^{l}(-y_i\log{a_i} - (1-y_i)\log(1-a_i))\; \rightarrow \;\min_\vec{w}
\end{gather*}
На одном объекте ошибка имеет вид:
\begin{equation}
    \label{eq:new_logloss}
    \text{logloss}\,(a, y) = -y\log{a} - (1-y)\log(1-a)
\end{equation}
И, \eqref{eq:new_logloss} тоже называется логистической функцией потерь. Легко показать, что \eqref{eq:old_logloss} и \eqref{eq:new_logloss} с подстановкой \eqref{eq:a_logregr}~--- одна и та же функция потерь с точностью до переобозначения классов $\{-1, +1\} \leftrightarrow \{0, 1\}$:
\begin{align*}
     &-[y=+1]\log{a} - (1-[y=+1])\log(1-a)\\
    =&-[y=+1]\log{\sigma\left(\left<\vec{x},\vec{w}\right>\right)} - (1-[y=+1])\log(1-\sigma\left(\left<\vec{x},\vec{w}\right>\right))\\
    =&-[y=+1]\log{\sigma\left(\left<\vec{x},\vec{w}\right>\right)} - [y=-1]\log\sigma\left(-\left<\vec{x},\vec{w}\right>\right)\\
    =&-\log{\sigma\left(\left<\vec{x},\vec{w}\right>y\right)}\\
    =&\log{(1+e^{-\left<\vec{x},\vec{w}\right>y})}=\mathcal{L}(M).
\end{align*}
Таким образом, мы показали, что вероятностный подход эквивалентен минимизации эмпирического риска. Вероятностный смысл можно придать и регуляризации, веса тоже рассматривать как случайную величину.

Напоследок перепишем в еще одной форме градиент функции потерь \eqref{eq:loss_okay} на одном объекте (при переименовании классов в $\{0, 1\}$, с учеотом небинаризованных ответов \eqref{eq:a_logregr}):
\begin{align}
    \pder[\mathcal{L}]{\vec{w}}&=-y \sigma\left(-\left<\vec{x},\vec{w}\right>\right)\cdot\vec{x} + \left( 1-y \right) \sigma\left(\left<\vec{x},\vec{w}\right>\right)\cdot\vec{x}\nonumber \\
    &=-y \cdot \left( 1-a \right)\cdot\vec{x} + \left( 1-y \right)\cdot a\cdot\vec{x}\nonumber\\
    &\label{eq:analogia1}= \left( a-y \right)\vec{x}.
\end{align}

\subsection{Многоклассовая логистическая регрессия}
Пусть у нас теперь не 2 класса, а $m$ классов: $1, \dots, m$. Начнем с вероятностной модели:
\begin{equation}
    \mathbb{P}(y=k\mid\vec{x}, \vec{w}_1,\dots,\vec{w}_{m})=\text{Softmax}_k
    \left(
        \left<\vec{x},\vec{w}_1\right>,
        \dots,
        \left<\vec{x},\vec{w}_m\right>
    \right),
\end{equation}
где $\text{Softmax}\colon\mathbb{R}^m\to \left( 0,1 \right)^{m}$ вычисляется по формуле
\begin{equation*}
    \text{Softmax}(\vec{s})=\left(\frac{e^{s_1}}{\sum_{t=1}^{m}e^{s_t}},\dots,\frac{e^{s_m}}{\sum_{t=1}^{m}e^{s_t}}\right)
\end{equation*}
Достаточно уметь предсказывать только $k-1$ класс, вероятность последнего будет получаться из нормировки. И модель действительно избыточна: ответы не изменятся при сдвиге всех весов. Чтобы устранить неоднозначность, положим $\vec{w}_m\coloneq\vec{0}$.

Теперь отдельно рассмотрим случай $m=2$. Вектор вероятностей классов будет иметь вид:
\begin{gather*}
    \left(
        \frac{e^{\left<\vec{x},\vec{w}_1\right>}}
             {e^{\left<\vec{x},\vec{w}_1\right>}+1},\,
        \frac{1}
             {e^{\left<\vec{x},\vec{w}_1\right>}+1}
    \right)
    =
    \left( 
        \sigma\left( \left<\vec{x},\vec{w}_1\right> \right),\,
        \sigma\left( -\left<\vec{x},\vec{w}_1\right> \right)
    \right) = \\
    = 
    \mbtw{\left\{ \vec{w}\coloneq-\vec{w}_1 \right\}}
    =
    \left( 
        1-\sigma\left( \left<\vec{x}, \vec{w}\right> \right),\,
        \sigma\left( \left<\vec{x}, \vec{w}\right> \right)
    \right)
\end{gather*}
Мы показали, что при $m=2$ параметрическая модель многоклассовой логистической регрессии эквивалента бинарной модели \eqref{eq:bernoulli}. И оценку весов $\vec{w}_1,\dots,\vec{w}_{m-1}$ в случае произвольного $m>1$ тоже можно искать с помощью метода максимального правдоподобия. Для удобства обозначим:
\begin{align*}
    y_{ik} &= [y_i = k], \\
    p_{ik} &= \frac{e^{\left<\vec{x}_i, \vec{w}_k\right>}}{\sum_{t=1}^{m} e^{\left<\vec{x}_i, \vec{w}_t\right>}},
\end{align*}
где $i\in \left\{ 1,\dots,l \right\}$, $k\in \left\{ 1,\dots,m \right\}$ — мы помним, что $\vec{w}_m\equiv \vec{0}$, но для удобства записи иногда будем оставлять его.

Функцию потерь можно вывести через правдоподобие:
\begin{align*}
    -l(\vec{w}) &=-\log\prod_{i=1}^{l}\mathbb{P}(y_i | \vec{x}_i, \vec{w}_1,\dots,\vec{w}_{m-1}) \\
    &= -\log \prod_{i=1}^{l}\prod_{k=1}^{m} p_{ik}^{y_{ik}}\\
    &=-\sum_{i=1}^{l}\sum_{k=1}^{m}y_{ik} \log p_{ik},
    \quad \mbtw{\text{(разделим на длину выборки)}} \\
Q(\mathbb{X}, \vec{w}) &= -\frac{1}{l}\sum_{i=1}^{l}\sum_{k=1}^{m}y_{ik} \log p_{ik}.
\end{align*}
Получили обобщение логлосса (кросс-энтропии) для нескольких классов. При решении задачи оптимизации понадобится градиент, в данном случае представляющий собой матрицу размера $d\times (m-1)$~--- найдем его. Сначала распишем потери на одном объекте:
\begin{align*}
    \mathcal{L}_i =-\sum_{k=1}^{m}y_{ik} \log p_{ik} &= -\sum_{k=1}^{m}y_{ik} \log \frac{e^{\left<\vec{x}_i, \vec{w}_k\right>}}{\sum_{t=1}^{m} e^{\left<\vec{x}_i, \vec{w}_t\right>}}\\
    &= -\sum_{k=1}^{m}y_{ik}{\left<\vec{x}_i, \vec{w}_k\right>}
    +\log{\sum_{t=1}^{m} e^{\left<\vec{x}_i, \vec{w}_t\right>}}\\
    &=
    \log\big( 1+\sum_{k=1}^{m-1}
    e^{\left<\vec{x}_i, \vec{w}_k\right>} \big) -
    \sum_{k=1}^{m-1}y_{ik}\left<\vec{x}_i, \vec{w}_k\right>
\end{align*}
Найдем ее градиент по вектору весов $\vec{w}_j$:
\begin{align}
    \label{eq:analogia2}
    \pder[\mathcal{L}_i]{\vec{w}_j} &= \frac{1}{ 1+\sum_{k=1}^{m-1}e^{\left<\vec{x}_i, \vec{w}_k\right>} }\cdot
    e^{\left<\vec{x}_i, \vec{w}_j\right>} \cdot \vec{x}_i - y_{ik}\vec{x}_i 
    = \left( p_{ij}-y_{ij} \right)\vec{x}_i.
\end{align}

Выражение \eqref{eq:analogia2} совпало с \eqref{eq:analogia1}! 

Тогда градиент полной функции потерь по произвольному вектору весов:
\begin{align*}
    \pder[Q]{\vec{w}_j} &= \frac{1}{l}\sum_{i=1}^{l}\left( p_{ij}-y_{ij} \right)\cdot\vec{x}_i.
\end{align*}
Объединяя в матрицу градиенты $Q$ по $\vec{w}_1,\dots,\vec{w}_{m-1}$ (то есть конкатенируя столбцы), получаем полную производную функции потерь.


% Предварительно вычислим:
% \begin{equation*}
%     \pder[\log p_{ik}]{\vec{w}_j}=
%     \frac{1}{p_{ik}}\cdot\pder[ p_{ik}]{\vec{w}_j}
%     =
% \end{equation*}
% \begin{equation*}
%     \pder[Q]{\vec{w}_j}=-\frac{1}{l}\sum_{i=1}^{l}\sum_{k=1}^{m}y_{ik} \pder[\log p_{ik}]{\vec{w}_j}
% \end{equation*}
% \begin{align*}
%     -l(\vec{w}) &=-\log\prod_{i=1}^{l}\mathbb{P}(y_i | \vec{x}_i, \vec{w}_1,\dots,\vec{w}_{m-1}) \\
%     &= -\log \prod_{i=1}^{l}\left(
%         \left(\frac{1}{1+\sum_{t=1}^{m-1}
%                  e^{\left<\vec{x}_i, \vec{w}_t\right>}}
%         \right)^{\left[y_i=m\right]}
%         \prod_{k=1}^{m-1}
%         \left(\frac{e^{\left<\vec{x}_i, \vec{w}_k\right>}}{1+\sum_{t=1}^{m-1} e^{\left<\vec{x}_i, \vec{w}_t\right>}}
%         \right)^{\left[y_i=k\right]}
%     \right)\\
%     &= -\log \prod_{i=1}^{l}\left(
%         \left(\frac{1}{1+\sum_{t=1}^{m-1}
%                  e^{\left<\vec{x}_i, \vec{w}_t\right>}}
%         \right)
%         \prod_{k=1}^{m-1}
%         e^{\left<\vec{x}_i, \vec{w}_k\right>\left[y_i=k\right]}
%     \right)\mbtw{,\quad y_{ik}\coloneq \left[y_i=k\right]}\\
%     &=-\log \prod_{i=1}^{l}\left(
%         \big({1+\sum_{k=1}^{m-1}
%                  e^{\left<\vec{x}_i, \vec{w}_k\right>}}
%         \big)^{-1}
%         \prod_{k=1}^{m-1}
%         e^{\left<\vec{x}_i, \vec{w}_k\right>y_{ik}}\right)\\
%     &=\sum_{i=1}^{l}\left(
%         \log\big( 1+\sum_{k=1}^{m-1}
%         e^{\left<\vec{x}_i, \vec{w}_k\right>} \big) -
%         \sum_{k=1}^{m-1}\left<\vec{x}_i, \vec{w}_k\right>y_{ik}
%     \right)\; \longrightarrow \;\min_{\vec{w}_1,\dots,\vec{w}_{m-1}}
% \end{align*}

\section{Эксперименты}

\subsection{Структура}
В задании предлагаются обучающая и тестовая выборка, составленные на основе соревнования \cite{kaggle}. Необходимо решить задачу бинарной классификации, реализовав логистическую регрессию, а также оптимизационные алгоритмы: градиентный спуск и стохастический градиентный спуск. В ходе экспериментов рассматривается множество гиперпараметров, в частности зависимость от времени и итераций, а также варианты предобработки текстовых данных.

Параметры модели рассматриваются последовательно, некоторые подбираются в комбинациях друг с другом. Оставшиеся фиксируются значениями по умолчанию или соображение по предыдущим этапам эксперимента. То же относится и к предобработке данных. Тем не менее в процессе добавления этапов предобработки, подбора новых параметров, старые иногда могут оказаться нерелевантны. 

Для оценки качества в задании предлагается использовать функцию потерь (усредненный логлосс с регуляризацией) и долю правильных ответов (accuracy). Чтобы более корректно оценивать алгоритм, измерения accuracy в ходе подбора гипермараметров производятся на отложенной выборке, составляющей примерно четверть исходной обучающей. Точное разбиение приведено в \autoref{table:split}. Проведя все необходимые эксперименты (для поиска параметров градиентных методов), мы обучим модель на всех исходных данных (обучающей выборки) и измерим качество на тестовой. В заданиях, связанных с предобработкой текстовых данных мы будем работать уже с полной обучающей выборкой, поскольку в задании требуется строить признаковое описание на ней.

\begin{table}[h!]
    \centering
    \begin{tabular}{@{}lccc@{}}
    \toprule
    \textit{Тип выборки} & \textbf{Обучающая} & \textbf{Отложенная} & \textbf{Тестовая} \\ \midrule
    \textit{Число объектов} & 40000 & 12061 & 20676 \\ \bottomrule
    \end{tabular}
    \caption{Разбиение по выборкам}
    \label{table:split}
\end{table}

% Также некоторые важные параметры модели (например, коэффициент регуляризации или порог бинаризации) в задании исследовать не предлагается. Но мы все равно подберем их на отложенной выборке ближе к концу.

Базовая предобработка датасета выполнена в соответствии с заданием, причем \verb!min_df!=5 (у \verb!CountVectorizer!). Если не обговаривается, далее у функций использованы базовые параметры по умолчанию ($\alpha=1$, $\beta=0$, \verb!tolerance!=$10^{-5}$, размер батча у SGD $500$, параметр регуляризации $\lambda=0$, т.к. модели оказались не склонными к переобучению).

Введен новый параметр \verb!intercept!, соответствующий смещению или добавлению константного признака, как было описано в теоретической части, далее он всегда будет будет использоваться.

\subsection{Темп обучения}
В задании предлагается использовать темп обучения
\begin{equation}
    \label{eq:lr}
    \eta_k=\frac{\alpha}{k^{\beta}},
\end{equation}
где $k$ — номер итерации (эпохи), $\alpha, \beta$ — константы. Поскольку $\alpha$ и $\beta$ входят в формулу \eqref{eq:lr} одноверменно, разумно подбирать их вместе. Для визуализации на каждом графике зафиксирован $\beta$ и варьируется $\alpha$, поскольку в теоретическое обоснование сходимости (стохастического) градиентного спуска с шагом \eqref{eq:lr} определяется именно показателем степени.

\subsubsection{Градиентный спуск}
Для обыкновенного градиентного спуска визуализируем зависимость функции потерь и точности от номера итерации. Группируем графики, как было обосновано выше, по значениям $\beta$.

\mpl{ab_gd_0}{Градиентный спуск, $\beta=0$. Крайние значения при $\alpha=10$ обрезаны.}
$\beta=0$ (\autoref{fig:ab_gd_0}) соответствует константному шагу. При больших значениях $\alpha$ имеется выраженная зигзагообразность и у графика функции потерь, и у доли правильных ответов. Особенно колебания проявляются на первых итерациях. При этом можно заметить, что $\alpha=10$, несмотря на нестабильное поведение, дает лучшее качество на некоторых итерациях! Но именно график по итерациям показывает, что за этим следует изменение в худшую сторону. При остальных константных шагах $\alpha$ поведение функции потерь и точности достаточно стабильное. Причем с уменьшением $\alpha$ алгоритм сходится медленнее.

\mpl{ab_gd_1}{Градиентный спуск, $\beta=0.1$. Крайние значения при $\alpha=10$ обрезаны.}
С добавлением показателя степени $\beta=0.1$ (\autoref{fig:ab_gd_1}) графики немного сглаживаются, а также можно видеть снижение разброса с ростом итерации. При $\alpha=10$ сходимость функции потерь ускорилась, но при малых значениях $\alpha$ оба графика быстрее выходят на асимптоту.

\mpl{ab_gd_2}{Градиентный спуск, $\beta=\frac{1}{2}$.}
При $\beta=\frac{1}{2}$ (\autoref{fig:ab_gd_2}) в полной мере видна монотонная зависимость от $\alpha$ как потерь, так и точности: с ростом $\alpha$ сходимость улучшается. Хотя при заданном $\beta$ тысячи итераций еще недостаточно для удовлетворения условия сходимости, графики уже становятся пологими, и имеет смысл настраивать число итераций только на больших $\alpha$.

\mpl{ab_gd_3}{Градиентный спуск, $\beta=1$.}
Когда мы возьмем $\beta=1$ (\autoref{fig:ab_gd_3}), градиентный спуск сходится достаточно быстро. Внутри алгоритма под <<сходмостью>> понимается выравнивание функции потерь, то есть отсутствие выраженных изменений на соседних итерациях. И при $\beta=1$ проявляется недостаток такого критерия останова: по точности видно, что веса не достигают оптимальных значений.

\mpl{ab_gd_4}{Градиентный спуск, $\beta=2$.}
Максимальное исследуемое $\beta=2$ (\autoref{fig:ab_gd_3}) только усиливает проблемы, возникшие при $\beta=1$. Алгоритмы сходятся очень быстро, но результирующее качество крайне низкое. Однако сохраняется монотонная зависимость от $\alpha$.

Итак, при больших значениях $\alpha$ можно получить наилучшее качество, но поведение вектора весов становится нестабильным. Уменьшать этот эффект можно с помощью увеличения параметра $\beta$. Но рост $\beta$ приводит к быстрому выходу функции потерь на асимптоту, и веса не успевают сойтись к нужным значениям, обеспечивающим высокое качество.

Неплохо проявили себя две стратегии. Первая (и простая по настройке)~--- работать с константным шагом ($\beta=0$), но при этом нужно брать $\alpha\approx1$, т.к. при чрезмерно больших значениях пропадет стабильность, а при меньших~--- замедляется сходимость и падает качество. Вторая~--- брать малое $\beta>0$ (в данном случае $0.1-0.5$) и тогда достаточно большие $\alpha\geqslant1$ могут дать не менее хороший результат.

\subsubsection{Стохастический градиентный спуск}
Теперь рассмотрим, как повлияют параметры $\alpha$ и $\beta$ на поведение стохастического градиентного спуска. Дизайн эксперимента совпадает с градиентым спуском. Только в данном случае вместо номера итерации используется, как предложено в задании, приближенный номер эпохи. Под данной величиной понимается Доля объектов, на которых уже считался градиент, относительно размера выборки. Эта величина имеет смысл, поскольку на каждом шаге нашего варианта SGD берется не один случайной объект, а подмножество (иногда такой подход называют mini-batch gradient descent).

Функция потерь и точность обновляются тогда, когда разница между текущим и предыдущим приближенным номером эпохи $>1$ (реализация допускает и более частое/редкое обновление), что в определенном смысле близко к итерации обыкновенного градиентного спуска.

\mpl{ab_sgd_0}{Стохастический градиентный спуск, $\beta=0$}
\mpl{ab_sgd_1}{Стохастический градиентный спуск, $\beta=0.1$}
\mpl{ab_sgd_2}{Стохастический градиентный спуск, $\beta=\frac{1}{2}$}
\mpl{ab_sgd_3}{Стохастический градиентный спуск, $\beta=1$}
\mpl{ab_sgd_4}{Стохастический градиентный спуск, $\beta=2$}

На \autoref{fig:ab_sgd_0}~--~\autoref{fig:ab_sgd_4} приведены графики функции потерь и точности на тех же наборах $\alpha$ и $\beta$. В целом поведение очень похоже на градиентный спуск. Аналогично на больших $\alpha$ достигается большее качество, рост $\beta$ стабилизирует поведение графиков. Отметим отличия: при константном шаге (\autoref{fig:ab_sgd_0}) и относительно небольшом (\autoref{fig:ab_sgd_0}) $\alpha$ точность выходит на асимтоту, но алгоритм при этом не останавливается. И действительно, константные шаги для стохастического градиента не гарантируют сходимость, но, например, при $\alpha=1$, поведение все-таки приемлемое. Важно помнить, что мы учимся не на одном объекте, а на батчах. Начиная с $\beta=\frac{1}{2}$ алгоритм работает более предсказуемо: точность и потери монотонно зависят от $\alpha$ и большие $\beta$ позволяют брать большие $\alpha$. Но при слишком сильном затухании ($\beta=2$, \autoref{fig:ab_sgd_4}) к оптимальным весам алгоритм не сходится.

Таким образом, выбор $\alpha$ и $\beta$ для SGD в данной задаче можно проводить с теми же двумя стратекиями, что и при обычном градиентном спуске. Простая~--- взять $\beta=0$ и $\alpha\approx 1$, но в данном случае нельзя особо увеличивать $\alpha$. Более сложная настройка~--- $\beta<2$, причем в при достаточно большом $\alpha$ имеет смысл и $\beta=1$, в то время как при $\beta=0.1$ лучше взять $\alpha\approx 1$.

\subsection{Начальное приближение}
Рассмотрим следующие начальные приближения для вектора весов $\vec{w}$:
\begin{enumerate}
    \item $\vec{w}_i=0$,
    \item $\vec{w}_i=1$,
    \item $\vec{w}_i\sim U[-\frac{1}{2d},\frac{1}{2d}]$,
    \item $\vec{w}_i\sim U[-\frac{1}{\sqrt{d}},\frac{1}{\sqrt{d}}]$,
    \item $\vec{w}_i=\frac{\left<\vec{y}, \vec{x}_i'\right>}{\left<\vec{x}_i',\vec{x}_i'\right>}$, где $\vec{y}$~--- вектор меток, $\vec{x}_i'$~--- вектор значений $i$-го признака.
\end{enumerate}
Идея 5-й инициализации взята из \cite{voron}. Хотя для этот используется в задачах с квадратичной функцией потерь, результат окажется интересным. 

\mpl{init_gd}{Инициализация весов, градиентный спуск}

На \autoref{fig:init_gd}, \autoref{fig:init_sgd} видно, что инициализация случайными значениями в окрестности 0 или непосредственно нулями приводит примерно к одинаковым результатом~--- у графиков специально включена прозрачность, поскольку они сливаются. Причем схожесть проявляется даже в том, что они все ведут себя достаточно зигзагообразно.

\mpl{init_sgd}{Инициализация весов, стохастический градиентный спуск}

Инициализация единицами дает наихудшие результаты. В нашего признакового пространства эта оценка начинает с предсказаний константой 1~--- из-за дисбаланса классов алгоритм стартует с точности, близкой к $0.3$. Функция потерь тоже достаточно велика и обрезана на обоих графиках. 

Куда интеревнее получилось с результатами при использовании 5-го начального приближения. В обыкновенном градиентном спуске (\autoref{fig:init_gd}) такое приближение сделало алгоритм более стабильным, чем при инициализации в окрестности нулей. В случае стохастического градиента (\autoref{fig:init_sgd}) приближение дало более быструю сходимость, чем при случайной инициализации, но чуть более медленную, чем при нулевом начальном приближении. Так или иначе, разница несущественна.

Таким образом, для данной задачи можно использовать любое из приведенных начальных приближений, кроме единиц. При выборе обыкновенного градиентного спуска стоит обратить внимание на 5-й вариант. В случае стохастического градиента удобно инициализировать нулями.

\subsection{Размер батча (для стохастического градиента)}
Мощность подвыборки, на которой пересчитывается градиент, имеет достаточно большое влияние на качество и скорость работы алгоритма. Скорость будет рассмотрена в следующем пункте, а сейчас рассмотрим, как будут изменяться кривые в уже привычных координатах (приближенный номер эпохи $\times$ функционал). Размеры батча рассмотрим по логарифмической сетке.

\mpl{bs_sgd_b0_iter}{Стохастический градиент, константный шаг}

Поскольку с уменьшением размера батча увеличивается число шагов, важно задуматься о показателе степени в темпе обучения \autoref{eq:lr}. На графиках \autoref{fig:bs_sgd_b0_iter} выбрано $\beta=0$. При константном шаге и маленьком ($1-10$ объектов) батче алгоритм не сходится. То есть функция потерь <<в целом>> приближается к нулю, однако постоянные сдвиги и относительно нечастый пересчет (фактически раз в эпоху) делают алгоритм крайне нестабильным. На правом графике видно, что точность даже падает. Добавление $\beta$ сглаживает работу алгоритма (\autoref{fig:bs_sgd_b05_iter})~--- в этом случае имеется сходимость и при мальеньком батче.

Когда мы берем соизмеримый с размером выборки батч (10 тыс. объектов), то алгоритм ведет себя аналогично обыкновенному градиентному спуску. Видно сходство с графиками \autoref{fig:ab_gd_0} и \autoref{fig:ab_gd_2}.

\mpl{bs_sgd_b05_iter}{Стохастический градиент, $\beta=\frac{1}{2}$}

Но по графику точности становится ясно, что лучше брать размер батча $100-1000$. В таком случае алгоритм сходится после относительно небольшого числа эпох, без выраженных зигзагов и получая высокую точность.

\subsection{Время работы}

Для наибольше ясности перестроим графики \autoref{fig:bs_sgd_b0_iter} и \autoref{fig:bs_sgd_b05_iter} относительно времени по оси абсцисс~--- получим \autoref{fig:bs_sgd_b0_time} и \autoref{fig:bs_sgd_b05_time}.

\mpl{bs_sgd_b0_time}{Стохастический градиент, константный шаг}

Если по некоторым причинам <<$17500$ секунд>> не выглядят пугающе, то это чуть меньше 5-ти часов. Ненулевое $\beta$ немного спасает ситуацию (\dots2 часа), но все равно, вывод очевиден: в нашей задаче слишком маленькие батчи запрещены к использованию. Попробуем зафиксировать комбинации параметров, при которых и градиентный спуск, и стохастический градиентный могут показать неплохой результат. 

\mpl{bs_sgd_b05_time}{Стохастический градиент, $\beta=\frac{1}{2}$}

На \autoref{fig:times2},  \autoref{fig:times4} показаны результаты. Выбирается несколько сидов для генерации начального приближения (в случае стохастического градиента и для выбора батчей).
\mpl{times2}{Работа алгоритмов при $\alpha=1.5,\; \beta=0.05$. <<$S$>> отмечено окончание работы.}
\mpl{times4}{Работа алгоритмов при $\alpha=10,\;\beta=\frac{3}{2}$. <<$S$>> отмечено окончание работы.}
Как видим, стохастический градиент в особенности быстр при большем $\beta$. В случае большего масштаба $\alpha$ и меньшего $\beta$ быстрее сходится обыкновенный градиентный спуск. При этом точность и функция потерь у случае стохастического градиента лучше.

\subsection{Промежуточные итоги по параметрам градиентных методов}

Итак, на данный момент мы провели анализ параметров стохастического градиентного спуска и сопоставили их друг с другом. Из результатов очевидно, что стохастический градиент предпочтительнее. На валидационной выборке мы попробовали разные комбинации~--- далее по умолчанию возьмем $\alpha=1.5$, $\beta=0.05$, начальное приближение из $\sim U[-\frac{1}{2d},\frac{1}{2d}]$. Обучим модель на полной обучающей выборке. В результате получим точность на тестовой: $0.8876$.

\subsection{Лемматизация и удаление стоп-слов}

Поробуем, помимо базовой предобработки, применить лемматизацию и удаление стоп-слов к нашему корпусу. Результаты приедены в \autoref{table:txt}.
\begin{table}[h!]
    \centering
    \begin{tabular}{@{}ccccc@{}}
    \toprule
    \multicolumn{1}{r}{\textit{лемматизация}} & - & + & - & + \\ 
    \multicolumn{1}{r}{\textit{удаление стоп-слов}} & - & - & + & + \\ \midrule
    {\ul число признаков} & 18253 & 16374 & 18109 & 16234 \\
    {\ul время работы, с} & 46 & 56 & 33 & 23 \\
    {\ul точность} & 0.8878 & 0.8878 & 0.8859 & 0.8870 \\ \bottomrule
    \end{tabular}
    \caption{Предобработка текста}
    \label{table:txt}
\end{table}

Из результатов видим, что лемматизация в значительной мере уменьшает размерность признакового пространства, но не понимжает качество. В то время как удаление стоп-слов ухудшает качество модели, несмотря на то что алгоритм быстрее заканчивает работу.

Далее оставляем лемматизацию.

\subsection{Настройка числовых признаков}

Теперь посмотрим, как повлияют на качество, скорость работы и размерность признакового пространства параметры числовых моделей~--- Bag of words и TFIDF.

\begin{table}[!h]
    \centering
    \begin{tabular}{@{}ccccccccc@{}}
    \toprule
    \multicolumn{1}{r}{\textit{min\_df}} & 1     & 3     & 5     & 10    & 20   & 30   & 40   & 45   \\ \midrule
    \begin{tabular}[c]{@{}c@{}}число\\ признаков\end{tabular}                      & 82991 & 23925 & 16374 & 10210 & 6646 & 5163 & 4298 & 3982 \\ \midrule
    \begin{tabular}[c]{@{}c@{}}время\\ работы, с\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}41\\ 88\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}39\\ 39\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}57\\ 38\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}39\\ 37\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}10\\ 7\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}14\\ 14\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}10\\ 14\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}34\\ 12\end{tabular} \\ \midrule
    точность &
      \begin{tabular}[c]{@{}c@{}}0.8902\\ 0.8929\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8875\\ 0.8916\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8878\\ 0.8916\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8896\\ 0.8915\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}\textbf{0.8912}\\ 0.8894\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8849\\ \textbf{0.8934}\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8881\\ 0.8925\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8837\\ 0.8907\end{tabular} \\ \bottomrule
    \end{tabular}
    \caption{Варьирование \texttt{min\_df}, в сдвоенных результатах сверху BoW, снизу TFIDF}
    \label{table:mindf}
\end{table}

Будем сначала удалять слишком редкие слова, увеличивая значение \verb!min_df!. Результаты приведены d \autoref{table:mindf}. Число признаков очень быстро падает с ростом \verb!min_df!~--- здесь все очевидно. А вот у точности нет такой монотонности. Модель bag of words почти не показывает закономерностей в данном параметре, а вот точность TFIDF, по-видимому, достигает максимума в окрестности 30. Возьмем, например, \verb!min_df!=25 и посмотрим как повлияет выбрасывание самых частых слов коллекции, за что отвечает параметр \verb!max_df!.

\begin{table}[!h]
    \centering
    \begin{tabular}{@{}cccccc@{}}
    \toprule
    \multicolumn{1}{r}{\textit{max\_df}} & 1    & 0.3  & 0.15 & 0.1  & 0.05 \\ \midrule
    число признаков                      & 5801 & 5790 & 5765 & 5747 & 5690 \\ \midrule
    время работы, с &
      \begin{tabular}[c]{@{}c@{}}8\\ 7\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}2\\ 13\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}3\\ 14\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}12\\ 16\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}6\\ 16\end{tabular} \\ \midrule
    точность &
      \begin{tabular}[c]{@{}c@{}}0.8890\\ 0.8903\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8885\\ 0.8926\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}\textbf{0.8890}\\ 0.8918\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8856\\ \textbf{0.8934}\end{tabular} &
      \begin{tabular}[c]{@{}c@{}}0.8870\\ 0.8929\end{tabular} \\ \bottomrule
    \end{tabular}
    \caption{Подбор \texttt{max\_df}, в сдвоенных результатах сверху BoW, снизу TFIDF}
    \label{table:maxdf}
\end{table}

Отметим, что TFIDF во всех случях дает лучшее качество, чем BoW. Время работы алгоритмов после фиксации числа признаков почти не зависит от параметров, а скорее случайно.

Причем мы помним, что выбрасывание стоп-слов ухудшило модель. Почему тогда здесь увеличение \verb!max_df! не снижает качество? Все очень просто: stop-words включает в себя в целом распространенные слова, в то время как \verb!max_df! удаляет высокочастостные объекты для данной коллекции. Например, в терминах сегодняшнего твиттера в роли таких слов могли бы выступить слова из Trends, на которые комментарии бывают и позитивными, и негативными.

\subsection{n-граммы}
Добавление n-грамм не улучшает качество и время в данной задаче, что сразу видно в \autoref{table:ngram}.
\begin{table}[!h]
    \centering
    \begin{tabular}{@{}cccccc@{}}
    \toprule
    \multicolumn{1}{r}{\textit{ngram\_range}} & (1, 1) & (1, 2) & (1, 3) & (1, 4) & (1, 5) \\ \midrule
    число признаков                           & 5747   & 18034  & 23092  & 24914  & 26288  \\ \midrule
    время работы, с                           & 18     & 43     & 58     & 67     & 66     \\ \midrule
    точность                                  & \textbf{0.8934} & 0.8923 & 0.8926 & 0.8929 & 0.8926 \\ \bottomrule
    \end{tabular}
    \caption{Добавление n-грамм}
    \label{table:ngram}
\end{table}

\subsection{Заключение}
Таким образом, наилучшая модель ($\alpha=1.5$, $\beta=0.05$, \verb!min_df=25!, \verb!max_df!=0.1, использование TFIDF; остальное~--- по умолчанию) дает на тестовой выборке качество 0.8934. Рассмотрим несколько ошибок, указывая в скобках тип: класс P~--- токсичный комментарий, N~--- не токсичный. Поскольку почти во всех комментариях присутствует ненормативная лексика, попробуем найти не самые страшные:

\begin{itemize}
    \item[1.] \texttt{':Dear god this site is horrible.'} (FP) Данный комментарий вне контекста вполне относится к классу P.
    \item[358.] \texttt{'666 the devil will get you all !!!!!!!!!!!!!!!!\\ !!!!!!!!!!!!!'} (FP) То же справедливо и здесь. Судя по остальным комментариям, основные ошибки алгоритма именно на тех объектах, которые действительно могут быть отнесены к положительному классу. И здесь проявляется ситуация, когда знаки препинания также содержат информациюю для классификации.
    \item[6483.] \texttt{'==The article was locked!==\\ I've got an account, but it is annoying how some silly dimwit caused\\ this to get locked!'} (FN) В данном случае сообщение выражает негодование человека в связи с отсутствием доступа к статье. Слова article, account, locked обычно не распространены в токсичных комментариях.
    \item[8528.] \texttt{'You are  a gimp'} (FN) Слово <<gimp>> сравнительно редко используется.
\end{itemize}
\newpage
\printbibliography
\end{document}